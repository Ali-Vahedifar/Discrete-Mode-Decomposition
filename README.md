# DMD+SMV: Discrete Mode Decomposition Meets Shapley Value for Robust Signal Prediction in Tactile Internet

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![IEEE INFOCOM 2025](https://img.shields.io/badge/IEEE-INFOCOM%202025-green.svg)](https://infocom2025.ieee-infocom.org/)

## ğŸ† Accepted at IEEE INFOCOM 2025

**Authors:** Mohammad Ali Vahedifar (Ali Vahedi) and Qi Zhang

**Affiliation:** DIGIT and Department of Electrical and Computer Engineering, Aarhus University, Denmark

**Acknowledgments:** This research was supported by:
- TOAST project, funded by the European Union's Horizon Europe research and innovation program under the Marie SkÅ‚odowska-Curie Actions Doctoral Network (Grant Agreement No. 101073465)
- Danish Council for Independent Research project eTouch (Grant No. 1127-00339B)
- NordForsk Nordic University Cooperation on Edge Intelligence (Grant No. 168043)

---

## ğŸ“– Abstract

The Tactile Internet (TI) requires ultra-low latency and high reliability to ensure stability and transparency in touch-enabled teleoperation. However, variable delays and packet loss present significant challenges to maintaining immersive haptic communication. This work proposes a novel predictive framework that integrates **Discrete Mode Decomposition (DMD)** with **Shapley Mode Value (SMV)** for accurate and timely haptic signal prediction.

- **DMD** decomposes haptic signals into interpretable intrinsic modes
- **SMV** evaluates each mode's contribution to prediction accuracy, aligned with goal-oriented semantic communication
- Combined **DMD+SMV** accelerates inference, enabling efficient communication and smooth teleoperation

### Key Results
| Method | 1-Sample Accuracy | 100-Sample Accuracy | 1-Sample Latency | 100-Sample Latency |
|--------|-------------------|---------------------|------------------|---------------------|
| **DMD+SMV (Ours)** | **98.9%** | **92.5%** | **0.056ms** | **2ms** |
| DMD | 96.9% | 90.0% | 0.05ms | 6.91ms |
| Baseline | 73.6% | 67.3% | 0.04ms | 1640.76ms |

---

## ğŸ—ï¸ Project Structure

```
dmd-smv-tactile-internet/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package installation
â”œâ”€â”€ pyproject.toml              # Modern Python packaging
â”‚
â”œâ”€â”€ configs/                     # Configuration files
â”‚   â”œâ”€â”€ default_config.yaml     # Default training configuration
â”‚   â”œâ”€â”€ transformer_config.yaml # Transformer-specific settings
â”‚   â”œâ”€â”€ resnet_config.yaml      # ResNet-specific settings
â”‚   â””â”€â”€ lstm_config.yaml        # LSTM-specific settings
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dmd/                     # Discrete Mode Decomposition
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ decomposition.py    # Core DMD algorithm
â”‚   â”‚   â”œâ”€â”€ wiener_filter.py    # Discrete Wiener filtering
â”‚   â”‚   â”œâ”€â”€ hilbert_transform.py # Discrete Hilbert transform
â”‚   â”‚   â””â”€â”€ optimization.py     # ADMM optimization
â”‚   â”‚
â”‚   â”œâ”€â”€ smv/                     # Shapley Mode Value
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ shapley_value.py    # Shapley value computation
â”‚   â”‚   â”œâ”€â”€ monte_carlo.py      # Monte Carlo approximation
â”‚   â”‚   â””â”€â”€ mode_valuation.py   # Mode valuation utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # Neural Network architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ transformer.py      # Transformer architecture
â”‚   â”‚   â”œâ”€â”€ resnet.py           # ResNet-32 architecture
â”‚   â”‚   â”œâ”€â”€ lstm.py             # LSTM architecture
â”‚   â”‚   â””â”€â”€ base_model.py       # Base model class
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                    # Data handling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py          # Dataset classes
â”‚   â”‚   â”œâ”€â”€ dataloader.py       # DataLoader utilities
â”‚   â”‚   â””â”€â”€ preprocessing.py    # Data preprocessing
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                # Training utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Main training loop
â”‚   â”‚   â”œâ”€â”€ losses.py           # Loss functions
â”‚   â”‚   â””â”€â”€ callbacks.py        # Training callbacks
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/              # Evaluation utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py          # Accuracy, PSNR, etc.
â”‚   â”‚   â”œâ”€â”€ inference.py        # Inference engine
â”‚   â”‚   â””â”€â”€ benchmarks.py       # Benchmarking utilities
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py           # Logging utilities
â”‚       â”œâ”€â”€ visualization.py    # Plotting and visualization
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â””â”€â”€ seed.py             # Reproducibility utilities
â”‚
â”œâ”€â”€ experiments/                 # Experiment scripts
â”‚   â”œâ”€â”€ train_all_models.py     # Train all architectures
â”‚   â”œâ”€â”€ evaluate_accuracy.py    # Accuracy evaluation
â”‚   â”œâ”€â”€ evaluate_inference.py   # Inference time evaluation
â”‚   â”œâ”€â”€ ablation_study.py       # Ablation studies
â”‚   â””â”€â”€ generate_figures.py     # Generate paper figures
â”‚
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ download_data.py        # Download dataset
â”‚   â”œâ”€â”€ prepare_data.py         # Prepare data for training
â”‚   â””â”€â”€ run_experiments.sh      # Run all experiments
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ test_dmd.py             # Test DMD module
â”‚   â”œâ”€â”€ test_smv.py             # Test SMV module
â”‚   â”œâ”€â”€ test_models.py          # Test neural networks
â”‚   â””â”€â”€ test_metrics.py         # Test evaluation metrics
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_dmd_visualization.ipynb
â”‚   â”œâ”€â”€ 03_smv_analysis.ipynb
â”‚   â””â”€â”€ 04_results_analysis.ipynb
â”‚
â”œâ”€â”€ results/                     # Results storage
â”‚   â”œâ”€â”€ figures/                # Generated figures
â”‚   â””â”€â”€ logs/                   # Training logs
â”‚
â””â”€â”€ docs/                        # Documentation
    â”œâ”€â”€ installation.md
    â”œâ”€â”€ usage.md
    â””â”€â”€ api_reference.md
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/alivahedi/dmd-smv-tactile-internet.git
cd dmd-smv-tactile-internet

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .
```

### Download Dataset

```bash
# Download the Kinaesthetic Interactions Dataset
python scripts/download_data.py
```

### Quick Training Example

```python
from src.dmd import DiscreteModeDcomposition
from src.smv import ShapleyModeValue
from src.models import TransformerPredictor
from src.training import Trainer

# Initialize DMD
dmd = DiscreteModeDcomposition(noise_variance=0.01)

# Decompose signal
modes, center_frequencies = dmd.decompose(signal)

# Compute Shapley Mode Values
smv = ShapleyModeValue()
mode_values = smv.compute(modes, model, validation_data)

# Train Transformer with important modes
trainer = Trainer(model=TransformerPredictor(), config=config)
trainer.train(train_data, val_data)
```

### Run Full Experiment Pipeline

```bash
# Run all experiments
bash scripts/run_experiments.sh

# Or run individual experiments
python experiments/train_all_models.py --config configs/default_config.yaml
python experiments/evaluate_accuracy.py --checkpoint best_model.pt
python experiments/generate_figures.py --output results/figures/
```

---

## ğŸ“Š Reproducing Paper Results

### Training All Models

```bash
python experiments/train_all_models.py \
    --architectures transformer resnet lstm \
    --methods baseline dmd dmd_smv \
    --window_sizes 1 5 10 25 50 100 \
    --epochs 200 \
    --seed 42
```

### Generate Main Results Figure (Figure 3)

```bash
python experiments/generate_figures.py \
    --figure accuracy_inference \
    --output results/figures/figure3.pdf
```

### Ablation Study (Mode Update Frequency)

```bash
python experiments/ablation_study.py \
    --update_intervals 40 90 100 \
    --architecture transformer \
    --output results/ablation/
```

---

## ğŸ“ˆ Results

### Accuracy Comparison (Figure 3)

Our DMD+SMV framework achieves:
- **98.9%** accuracy for 1-sample prediction (Transformer)
- **92.5%** accuracy for 100-sample prediction (Transformer)
- **820Ã— speedup** compared to baseline methods

### PSNR Results (Figure 4)

- **29.5 dB** PSNR at W=1 for human side
- **27.5 dB** PSNR at W=1 for robot side
- Consistent **9-10 dB improvement** over baseline across all horizons

### Inference Time (Table I & II)

| Architecture | DMD+SMV | DMD | Baseline |
|--------------|---------|-----|----------|
| Transformer | 2.85ms | 7.30ms | 1640ms |
| ResNet-32 | 4.30ms | 10.45ms | 2059ms |
| LSTM | 6.00ms | 15.2ms | 2616ms |

### FLOPs and FLOPS Comparison (Table III)

| Architecture | FLOPs (DMD) | FLOPs (DMD+SMV) | FLOPS (DMD) | FLOPS (DMD+SMV) |
|--------------|-------------|-----------------|-------------|-----------------|
| LSTM | 3.4Ã—10â· | 2.1Ã—10â¶ | 2.24Ã—10â¹ | 0.35Ã—10â¹ |
| ResNet-32 | 11.2Ã—10â· | 8.6Ã—10â¶ | 10.72Ã—10â¹ | 2Ã—10â¹ |
| Transformer | 19.3Ã—10â· | 14.8Ã—10â¶ | **26.4Ã—10â¹** | **5.19Ã—10â¹** |

---

## ğŸ”— Links

- **Paper:** IEEE INFOCOM 2025 Proceedings
- **Code:** [github.com/Ali-Vahedifar/Discrete-Mode-Decomposition](https://github.com/Ali-Vahedifar/Discrete-Mode-Decomposition.git)
- **Dataset:** [Kinaesthetic Interactions Dataset (Zenodo)](https://doi.org/10.5281/zenodo.14924062)

---

## ğŸ”§ Configuration

### Default Configuration

```yaml
# configs/default_config.yaml
training:
  epochs: 200
  batch_size: 64
  learning_rate: 0.001
  lr_decay_epochs: [80, 120, 170]
  lr_decay_factor: 0.005
  dropout: 0.1

dmd:
  noise_variance: 0.01
  epsilon1: 1e-6
  epsilon2: 1e-6
  kappa1: 1e-3
  kappa2: 1e-3

smv:
  tolerance: 0.01
  max_iterations: 1000

evaluation:
  window_sizes: [1, 5, 10, 25, 50, 100]
  num_runs: 10
```

---

## ğŸ“š Citation

If you use this code in your research, please cite our paper:

```bibtex
@inproceedings{vahedifar2025dmd,
  title={Discrete Mode Decomposition Meets Shapley Value: Robust Signal Prediction in Tactile Internet},
  author={Vahedifar, Mohammad Ali and Zhang, Qi},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications},
  year={2025},
  organization={IEEE}
}
```

---

## ğŸ“§ Contact

- **Mohammad Ali Vahedifar (Ali Vahedi)**: av@ece.au.dk
- **Qi Zhang**: qz@ece.au.dk

**Institution:** DIGIT and Department of Electrical and Computer Engineering, Aarhus University, Denmark

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [TOAST Doctoral Network](https://toast-dn.eu/) - EU Horizon Europe Program
- [Danish Council for Independent Research](https://dff.dk/) - eTouch Project
- [NordForsk](https://www.nordforsk.org/) - Nordic Edge Intelligence Cooperation
- [Kinaesthetic Interactions Dataset](https://doi.org/10.5281/zenodo.14924062)

---

## ğŸ“œ Changelog

### v1.0.0 (2025)
- Initial release
- Full implementation of DMD and SMV algorithms
- Support for Transformer, ResNet-32, and LSTM architectures
- Comprehensive evaluation framework
- Paper reproduction scripts
